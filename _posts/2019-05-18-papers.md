---
title: 如何阅读英文论文
date: 18-05-2019
categories: 
- Natural Language Processing
tags: 
- learning
- NLP
---



上周末我拍了一支8分钟的 VLOG，发在微博（@思南说），讲我是如何阅读 NLP 论文的。不少读者在看完后留了正面反馈。我打算在这篇文章里把视频里的内容整理出来，顺便解答几个疑问，方便大家以后回顾。



读 NLP 论文和读任何领域的英文论文相比并无本质区别，以下建议也同样适用。

#### 1. 读英文论文的顺序很重要

英文学术写作的范式固定、风格统一，与其他类别文体风格差距很大，因此为了更有效快速地获取论文中的信息，最好不要像看小说一样从书第一页翻到最后一页，从一段的第一句看到最后一句。我是按什么顺序来高效看论文的呢？

##### a. 标题、日期、作者与组织、会议期刊

我拿到一篇论文会第一时间看这些 metadata。通过标题快速推测论文主题，通过发表日期确认论文的时效，通过作者组织猜测论文重要性与"赞助方"，通过是否参加过重要学术会议或期刊来确认论文是否同行审议过。

##### b. 全文结构

接下来我会从头到位快速翻一遍，浏览论文结构，看看小标题和图表，对有什么章节、哪个章节在什么位置心中有数。

##### c. 摘要、序言、结果、结论

接着就开始正式看论文内容了。我会先仔细看摘要和序言 (abstract & introduction)，了解这篇论文的主题、亮点、贡献、局限等。接下来我会直接翻到论文后面，开始看结果和结论 (results / discussions / conclusion) 章节。理工科论文的结论一般很短，通常只是对序言的转述，所以没必要太仔细去看；文科论文结论段可能会长得多，会更值得好好看。

这一步可以有效减少"好不容易看完整篇论文却一头雾水不知所云"的症状。

##### d. 中间章节

对于中间所有章节，我都是跳着看的。先看哪一节后看哪一节，哪一节细看哪一节略看，这些取决于兴趣和重要性。比如 NLP 论文一般都在讨论模型算法，发明新模型或改进现有模型等，所以最重要的内容往往是 model architecture 这一章。重要章节值得认真读完每一句话。不重要的章节或已经熟悉的背景知识就可以略看。

##### e. 章节段落内部

英文学术写作的范式之一就是，一章中第一段最重要，一段中第一句话最重要。特别是每段的第一句话，往往已经概括了整段的内容。所以在看论文的时候，一章之内，我会先看所有段落的第一句话，对该段内容有个初步理解，接着带着这个意识和自己的问题再去深入看剩下的细节。

#### 2. 公式与图表

NLP 论文不可避免地会涉及看起来很复杂的数学公式。有些数学基础没那么好的同学因此对直接阅读英文论文发怵。其实大不必如此。NLP 论文中的数学公式就算全部跳过，也不太会影响对整篇文章的理解。如果时间有限，也可以挑着看重要的公式，也就是那些公式后面特意标了号码的。就算只是一眼扫过，也算混了一次脸熟，次数多了，以后就有可能可以认出那些重复出现的重要公式。

比起公式，其实图表的价值更高，更值得好好研究。图表浓缩了大量信息，且比文字更加直观，非常值得结合文字好好理解。

#### 3. 辅助资料

当你把以上所有步骤都做到了后，是不是就一定能看懂论文了呢？当然不是。每人的知识储备水平不同，每篇论文的理解难度不同，集中精力看完一篇论文却还是对其内容一知半解实在是再正常不过的事。此时就应该去互联网上找更多的辅助资料来帮助理解。越重要的论文就会有越多的人来解读，网上能找到的资料也就越多。

比如，我在视频中拿来举例的那篇解释谷歌 Transformer 的重要论文《Attention is all you need》在网上就能找到非常多的解读文章、视频。我在读完论文后接着看了下面三个辅助视频，对我自己的理解非常有帮助。

[Yannic Kilcher: Attention is all you need](https://youtu.be/iDulhoQ2pro). 

Stanford CS224N (Winter 2017): [Lecture 10 Neural Machine Translation and Models with Attention](https://youtu.be/IxQtK2SjWWM). 

Stanford CS224N (Winter 2019): [Transformers and Self-Attention](https://youtu.be/5vcj8kSwBCY).

（请科学上网）

重点推荐第一个视频，浅入深出，讲得特别好。

#### 4. 去哪儿找论文

有人问去哪里能找到这样的论文。如果是专门 NLP 领域内论文的话，ACL 的[历年论文选集](https://aclweb.org/anthology)就是个开始的好地方。另外，大多数 NLP 网课都会推荐与每一节课内容相关的重要论文，比如 Stanford CS224N 的主页上就列了很多。最后，当你开始读论文后，就会很自然地顺着一篇论文引用文献的藤摸到更多相关论文。



好啦，希望以上内容对你有所帮助！

