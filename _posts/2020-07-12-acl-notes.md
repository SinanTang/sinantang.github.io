---
title: My notes for ACL 2020
date: 12-07-2020
categories:
- Natural Language Processing
tags:
- NLP
---

![acl-2020](../../../../../assets/images/acl-submissions.png){:style="margin:0 auto"}

来聊个两分钱的刚刚过去的ACL吧！这个周虽然准备好了啥事不干只看会议论文报告，奈何头痛胃痛轮番上阵，确实没能看很多论文，加上我也不是专业搞研究的，所以只能聊聊我的直观感受。

神经网络和深度学习已经火了好些年，虽然它们落实到业界里的应用基本还处于小范围尝鲜和哄风投阶段，但ACL作为行业最前沿的学术会议，今年明显释放出“大家可以考虑反思调整研发方向”的信号；不再去不求甚解追求越来越“深”的机器学习训练模型，或是追求用更多数据训练泛用途的模型。



**信号一**：在今年的Keynote演讲《Rewriting the Past: Assessing the Field through the Lens of Language Generation》中，Kathleen McKeown教授通过概述NLP整个领域的前世今生，给众研究者提出了几点未来研究方向的建议：

![keynote finalwords](../../../../../assets/images/acl-keynote.png){:style="margin:0 auto"}

我想，McKeown教授并不是在反对在训练fancy深度模型的路上越走越远，而是不赞成不求甚解的算法狂潮，提醒大家要为有意义的用途训练模型，要注重模型的可解释性（最起码应该做到定性分析一下输出结果吧），而不是一心追求更高的分数。

以语言生成（language generation）领域为例，McKeown教授点出现有机器学习算法在生成语言时与人类说话写字时的根本不同：人说话写字时有目的性，有计划，说我们认为的真话（写到这儿我忍不住插一句，也不是所有人类的发言都能够上这个标准…）；而算法则是在学习已有数据的基础上（非常笼统地讲）进行某种字符概率游戏。这个判断当然没错啦，让算法进一步模拟真实人脑的思维过程是一个存在很久了的对现有机器学习算法的主流批评声音。但从另一方面说，我一直认为这种看法反射出的是人类的自恋：算法为什么就一定要模拟人类行为呢？算法模型的最终目标就是人类自己吗？「*Address what matters*」——在我看来，努力让算法无限接近人类行为并不是what matters，也许现有NLP模型有更好的目标，比如成为辅助而非替代人类的工具，或者让机器学习模型更彻底地从计算语言学范畴里剥离出来，专心发展成任何学科都能拿来即用的量化工具。



不管怎么说，McKeown教授的演讲非常值得一看，就算是NLP的门外汉也不妨碍理解演讲主题。如果你对人工智能领域有一点兴趣，不妨去看看演讲视频回放。



**信号二**：今年的Best Theme Paper颁给了《Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data》。这篇论文确实精彩！这种通过（不太花钱的）认知思维实验来阐释论点的文章在秀各种fancy模型的主流NLP论文里独树一帜，简直是高了不止一个段位。这篇论文中的“章鱼思维实验”预计将会成为NLU业内的一个经典隐喻。抛开颇具创意的论文形式不说，这篇文章的论点落在“对语言形式的学习无法到达语言理解的目的”上。*Meaning isn't in form; rather, languages are rich, dense ways of providing cues to communicative intents.* 语言学家的优雅在这篇论文中处处显露出来。这个观点呼应了McKeown教授的演讲——「Bring language back to NLP」，这第一步是提醒众算法研究者们：机器算法不是自然语言，意义不在形式，既然大家声称自己在研究“自然语言处理”，那请先搞懂自然语言是什么吧！

语言学等认知学科是否会重新成为接下来NLP/AI发展的灵感之源和指路标还很难说，但很清楚的是现有机器学习算法模型不会是终点。



**信号三**：对近十年神经网络深度学习热的反思还体现在近两年越来越受人重视的“机器学习与伦理问题”和“机器学习模型的可解释性”上。在这些方面ACL也专门设立了独立的track来收集呈现论文。除了“Ethics and NLP”、“Interpretation and Analysis of Models for NLP”这两个新增track之外，今年还新增了“Theory and formalism”和“Theme: Taking stock of where we've been and where we're going”。这些反映了近年来NLP领域的发展在引起太多外界关注后，尝试从内部开始应对这些争议。有时确实是这样：业内人士心知一切离真正的人工智能可还差得远呢，但外行人因为不了解日趋复杂的计算机非线性建模，已经开始担忧被媒体吹嘘上天的AI的负面影响。当一个行业的社会影响力和风投吸金力越来越大时，它确实需要承担越来越重的社会责任。最起码，让机器学习模型变得更透明这个发展方向是一件双赢的事。

有些人沉迷于把NLP神秘化，这样就可以利用噱头来博关注拉投资，但这也会加大行内行外的距离，导致不信任和争议；与其如此，不如多多向大众科普何为自然语言处理何为机器学习，更进一步地，可以鼓励其他行业从业者使用NLP研究成果来帮助他们的工作（the democratisation of AI），揭开这层神秘的面纱，会更有利于这个行业的未来发展。
